# Building Baby Brains

Agents seem powerful, but getting a consistent result is harder than it looks, especially across diverse tasks.

This is my attempt to develop a system where small teams of agents get the right context at the right time, and through pre-defined workflows can achieve large objectives by continuously breaking them down into smaller pieces.

Current configuration:

- local LLM running with [Text generation web UI](https://github.com/oobabooga/text-generation-webui)
  - temperature 0.01
  - seed 1234567890
  - currently testing with miqu-70b-q5_k_m
- agents powered by [crewAI](https://crewai.io)

Folder structure:

- tools: each file contains a class for a type of tool and tool functions defined within as static methods
- agents: the `agents_v2.py` file contains the latest class definition for agents
- context: the `context.md` file is a placeholder test to see if the LLM can complete a simple task. In the future this would either exist already or be generated by an LLM to summarize and state necessary context to complete an objective.

To develop locally:

- (optional) use a virtual env, I'm using [miniconda] as an example:
  - create: `conda create -n crewai python=3.11`
  - activate: `conda activate crewai`
- install dependencies: `pip install -r requirements.txt`
- copy `.env.example` to `.env`
- configure `.env` with base LLM info ([see docs for more info](https://docs.crewai.com/how-to/LLM-Connections/#configuration-examples))
- run python file for the crew, currently `python crew-test-v2.py`

> [!WARNING]
> This is a work in progress, things will change, some features will work, some won't, and contributions are welcome. Let's figure out how to make useful agents together!

> [!CAUTION]
> By default agents have file system tools, you run this code at your own risk.
